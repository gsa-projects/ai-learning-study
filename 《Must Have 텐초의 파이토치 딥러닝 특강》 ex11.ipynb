{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1JiFjYV6BM6MsLlV6wRNnRHAZbr4x-0YB","timestamp":1699059297197}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import files\n","file = files.upload()"],"metadata":{"id":"TzpHyKhSShGq","executionInfo":{"status":"ok","timestamp":1699060143345,"user_tz":-540,"elapsed":12974,"user":{"displayName":"류현승","userId":"17577509123803272784"}},"outputId":"88f5fe95-ac7f-4328-f5f9-880d384b61fd","colab":{"base_uri":"https://localhost:8080/","height":75}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-f3715138-cf8e-42be-ad71-6b81eeeb2aff\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-f3715138-cf8e-42be-ad71-6b81eeeb2aff\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving CH11.txt to CH11.txt\n"]}]},{"cell_type":"markdown","source":["# 데이터 확인해보기"],"metadata":{"id":"7hN7LNjvklsT"}},{"cell_type":"code","source":["import string\n","\n","l = []\n","\n","\n","# 한글 텍스트 파일을 읽기 위해 utf-8 인코딩으로 읽어옴\n","with open(\n","    \"CH11.txt\",\n","    'r', encoding=\"utf-8\") as f:\n","   lines = f.read().split(\"\\n\")\n","   for line in lines:\n","       # 특수 문자를 지우고 모든 글자를 소문자로 변경\n","       txt = \"\".join(v for v in line if v not in string.punctuation).lower()\n","       l.append(txt)\n","\n","print(l[:5])"],"metadata":{"id":"_jmEcVHzkm3R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699062194091,"user_tz":-540,"elapsed":21,"user":{"displayName":"류현승","userId":"17577509123803272784"}},"outputId":"89d584dc-3c50-4134-fb3e-80f7d6cc496f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['go\\t가', 'hi\\t안녕', 'run\\t뛰어', 'run\\t뛰어', 'who\\t누구']\n"]}]},{"cell_type":"markdown","source":["# BOW를 만드는 함수 정의"],"metadata":{"id":"y2UcLB0plJ_h"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","\n","from torch.utils.data.dataset import Dataset\n","\n","SOS = 0\n","EOS = 1\n","def get_BOW(corpus):  # 문장들로부터 BOW를 만드는 함수\n","   BOW = {\"<SOS>\": SOS, \"<EOS>\": EOS}  # ❶ <SOS> 토큰과 <EOS> 토큰을 추가\n","\n","   # ❷ 문장 내 단어들을 이용해 BOW를 생성\n","   for line in corpus:\n","       for word in line.split():\n","           if word not in BOW.keys():\n","               BOW[word] = len(BOW.keys())\n","\n","   return BOW"],"metadata":{"id":"dJhKq_3rlKoS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 학습에 사용할 데이터셋 정의"],"metadata":{"id":"6POM6L3ulRfz"}},{"cell_type":"code","source":["class Eng2Kor(Dataset):  # 학습에 이용할 데이터셋\n","   def __init__(\n","       self,\n","       pth2txt=\\\n","       \"CH11.txt\"):\n","        self.eng_corpus = []  # 영어 문장이 들어가는 변수\n","        self.kor_corpus = []  # 한글 문장이 들어가는 변수\n","\n","        self.device = device\n","\n","        with open(pth2txt, 'r', encoding=\"utf-8\") as f:\n","            lines = f.read().split(\"\\n\")\n","\n","            for line in lines:\n","                # 특수 문자와 대문자 제거\n","                txt = \"\".join(\n","                    v for v in line if v not in string.punctuation\n","                ).lower()\n","\n","                engtxt = txt.split(\"\\t\")[0]\n","                kortxt = txt.split(\"\\t\")[1]\n","\n","                # 길이가 10 이하인 문장만 사용\n","                if len(engtxt.split()) <= 10 and len(kortxt.split()) <= 10:\n","                    self.eng_corpus.append(engtxt)\n","                    self.kor_corpus.append(kortxt)\n","\n","        self.engBOW = get_BOW(self.eng_corpus)\n","        self.korBOW = get_BOW(self.kor_corpus)\n","   # 문장을 단어별로 분리하고 마지막에 <EOS>를 추가\n","   def gen_seq(self, line):\n","       seq = line.split()\n","       seq.append(\"<EOS>\")\n","\n","       return seq\n","   def __len__(self): # ❶\n","       return len(self.eng_corpus)\n","\n","   def __getitem__(self, i): # ❷\n","       # 문자열로 되어 있는 문장을 숫자 표현으로 변경\n","       data = np.array([\n","            self.engBOW[txt] for txt in self.gen_seq(self.eng_corpus[i])])\n","\n","       label = np.array([\n","            self.korBOW[txt] for txt in self.gen_seq(self.kor_corpus[i])])\n","\n","       return data, label"],"metadata":{"id":"PSPo_poKlSLB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 학습에 사용할 데이터 로더 정의"],"metadata":{"id":"85apUvjIlble"}},{"cell_type":"code","source":["def loader(dataset):  # 데이터셋의 문장을 한문장씩 불러오기 위한 함수\n","   for i in range(len(dataset)):\n","       data, label = dataset[i]\n","\n","       # ❶ 데이터와 정답을 반환\n","       yield torch.tensor(data), torch.tensor(label)"],"metadata":{"id":"4cmyhHzvlcwe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 인코더 정의"],"metadata":{"id":"bu3VN0CzlpPi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7uyIraNiv0sl"},"outputs":[],"source":["import torch.nn as nn\n","\n","\n","class Encoder(nn.Module):\n","   def __init__(self, input_size, hidden_size):\n","       super(Encoder, self).__init__()\n","\n","       self.embedding = nn.Embedding(input_size, hidden_size)\n","       self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","   def forward(self, x, h):\n","       # ❶ 배치차원과 시계열 차원 추가\n","       x = self.embedding(x).view(1, 1, -1)\n","       output, hidden = self.gru(x, h)\n","       return output, hidden"]},{"cell_type":"markdown","source":["# 디코더 정의"],"metadata":{"id":"qa0sxwSNl6D4"}},{"cell_type":"code","source":["class Decoder(nn.Module):\n","   def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=11):\n","       super(Decoder, self).__init__()\n","\n","       # 임베딩층 정의\n","       self.embedding = nn.Embedding(output_size, hidden_size)\n","\n","       # 어텐션 가중치를 계산하기 위한 MLP층\n","       self.attention = nn.Linear(hidden_size * 2, max_length)\n","\n","       #특징 추출을 위한 MLP층\n","       self.context = nn.Linear(hidden_size * 2, hidden_size)\n","\n","       # 과적합을 피하기 위한 드롭아웃 층\n","       self.dropout = nn.Dropout(dropout_p)\n","\n","       # GRU층\n","       self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","       # 단어 분류를 위한 MLP층\n","       self.out = nn.Linear(hidden_size, output_size)\n","\n","       # 활성화 함수\n","       self.relu = nn.ReLU()\n","       self.softmax = nn.LogSoftmax(dim=1)\n","\n","   def forward(self, x, h, encoder_outputs):\n","       # ➊입력을 밀집 표현으로\n","       x = self.embedding(x).view(1, 1, -1)\n","       x = self.dropout(x)\n","\n","       # ➋어텐션 가중치 계산\n","       attn_weights = self.softmax(\n","           self.attention(torch.cat((x[0], h[0]), -1)))\n","\n","       # ➌어텐션 가중치와 인코더의 출력을 내적\n","       attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                encoder_outputs.unsqueeze(0))\n","\n","       # ➍인코더 각 시점의 중요도와 민집표현을 합쳐\n","       # MLP층으로 특징 추출\n","       output = torch.cat((x[0], attn_applied[0]), 1)\n","       output = self.context(output).unsqueeze(0)\n","       output = self.relu(output)\n","\n","       # ➎GRU층으로 입력\n","       output, hidden = self.gru(output, h)\n","\n","       # ➏예측된 단어 출력\n","       output = self.out(output[0])\n","\n","       return output"],"metadata":{"id":"YtgwsDwpl3Au"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 학습에 필요한 요소 정의"],"metadata":{"id":"kP9exMqrmAXq"}},{"cell_type":"code","source":["import random\n","import tqdm\n","\n","from torch.optim.adam import Adam\n","\n","\n","# 학습에 사용할 프로세서 정의\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","# 학습에 사용할 데이터셋 정의\n","dataset = Eng2Kor()\n","\n","\n","# 인코더 디코더 정의\n","encoder = Encoder(input_size=len(dataset.engBOW), hidden_size=64).to(device)\n","decoder = Decoder(64, len(dataset.korBOW), dropout_p=0.1).to(device)\n","# 인코더 디코더 학습을 위한 최적화 정의\n","encoder_optimizer = Adam(encoder.parameters(), lr=0.0001)\n","decoder_optimizer = Adam(decoder.parameters(), lr=0.0001)"],"metadata":{"id":"7bkcuNpCl8T_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 학습 루프 정의"],"metadata":{"id":"riaFqRGnmQ6N"}},{"cell_type":"code","source":["for epoch in range(30):\n","   iterator = tqdm.tqdm(loader(dataset), total=len(dataset))\n","   total_loss = 0\n","\n","   for data, label in iterator:\n","       data = torch.tensor(data, dtype=torch.long).to(device)\n","       label = torch.tensor(label, dtype=torch.long).to(device)\n","\n","       # 인코더의 초기 은닉 상태\n","       encoder_hidden = torch.zeros(1, 1, 64).to(device)\n","       # 인코더의 모든 시점의 출력을 저장하는 변수\n","       encoder_outputs = torch.zeros(11, 64).to(device)\n","\n","       encoder_optimizer.zero_grad()\n","       decoder_optimizer.zero_grad()\n","\n","       loss = 0\n","       for ei in range(len(data)):\n","           # ➊한 단어씩 인코더에 넣어줌\n","           encoder_output, encoder_hidden = encoder(\n","               data[ei], encoder_hidden)\n","           # ❷인코더의 은닉 상태를 저장\n","           encoder_outputs[ei] = encoder_output[0, 0]\n","\n","       decoder_input = torch.tensor([[0]]).to(device)\n","\n","       # ❸인코더의 마지막 은닉 상태를 디코더의 초기 은닉 상태로 저장\n","       decoder_hidden = encoder_hidden\n","       use_teacher_forcing = True if random.random() < 0.5 else False  # ❶\n","\n","       if use_teacher_forcing:\n","           for di in range(len(label)):\n","               decoder_output = decoder(\n","                   decoder_input, decoder_hidden, encoder_outputs)\n","\n","               # 직접적으로 정답을 다음 시점의 입력으로 넣어줌\n","               target = torch.tensor(label[di], dtype=torch.long).to(device)\n","               target = torch.unsqueeze(target, dim=0).to(device)\n","               loss += nn.CrossEntropyLoss()(decoder_output, target)\n","               decoder_input = target\n","       else:\n","           for di in range(len(label)):\n","               decoder_output = decoder(\n","                   decoder_input, decoder_hidden, encoder_outputs)\n","\n","               # ➊ 가장 높은 확률을 갖는 단어의 인덱스가 topi\n","               topv, topi = decoder_output.topk(1)\n","               decoder_input = topi.squeeze().detach()\n","\n","               # 디코더의 예측값을 다음 시점의 입력으로 넣어줌\n","               target = torch.tensor(label[di], dtype=torch.long).to(device)\n","               target = torch.unsqueeze(target, dim=0).to(device)\n","               loss += nn.CrossEntropyLoss()(decoder_output, target)\n","\n","               if decoder_input.item() == 1:  # <EOS> 토큰을 만나면 중지\n","                   break\n","       # 전체 손실 계산\n","       total_loss += loss.item()/len(dataset)\n","       iterator.set_description(f\"epoch:{epoch+1} loss:{total_loss}\")\n","       loss.backward()\n","\n","       encoder_optimizer.step()\n","       decoder_optimizer.step()\n","\n","torch.save(encoder.state_dict(), \"attn_enc.pth\")\n","torch.save(decoder.state_dict(), \"attn_dec.pth\")"],"metadata":{"id":"Tl0YqShCmCO9","executionInfo":{"status":"ok","timestamp":1699062193748,"user_tz":-540,"elapsed":1458031,"user":{"displayName":"류현승","userId":"17577509123803272784"}},"outputId":"ef558321-cc35-4aed-dd3a-7c3662224ce8","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/3592 [00:00<?, ?it/s]<ipython-input-39-28b1ef772998>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  data = torch.tensor(data, dtype=torch.long).to(device)\n","<ipython-input-39-28b1ef772998>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  label = torch.tensor(label, dtype=torch.long).to(device)\n","<ipython-input-39-28b1ef772998>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  target = torch.tensor(label[di], dtype=torch.long).to(device)\n","epoch:1 loss:0.014254749485007372:   0%|          | 0/3592 [00:00<?, ?it/s]<ipython-input-39-28b1ef772998>:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  target = torch.tensor(label[di], dtype=torch.long).to(device)\n","epoch:1 loss:23.175205588075283: 100%|██████████| 3592/3592 [00:54<00:00, 66.20it/s]\n","epoch:2 loss:22.095655346235354: 100%|██████████| 3592/3592 [00:55<00:00, 64.91it/s]\n","epoch:3 loss:21.723764384377006: 100%|██████████| 3592/3592 [00:55<00:00, 65.06it/s]\n","epoch:4 loss:21.149789538574655: 100%|██████████| 3592/3592 [00:55<00:00, 64.55it/s]\n","epoch:5 loss:21.19292260444244: 100%|██████████| 3592/3592 [00:55<00:00, 64.55it/s]\n","epoch:6 loss:21.074827376280158: 100%|██████████| 3592/3592 [00:55<00:00, 65.02it/s]\n","epoch:7 loss:20.906093106105214: 100%|██████████| 3592/3592 [00:58<00:00, 61.69it/s]\n","epoch:8 loss:20.676779308470447: 100%|██████████| 3592/3592 [00:59<00:00, 60.74it/s]\n","epoch:9 loss:20.443139549087576: 100%|██████████| 3592/3592 [00:59<00:00, 60.59it/s]\n","epoch:10 loss:20.241148190336478: 100%|██████████| 3592/3592 [01:00<00:00, 59.77it/s]\n","epoch:11 loss:19.96203057272132: 100%|██████████| 3592/3592 [01:00<00:00, 59.80it/s]\n","epoch:12 loss:20.07940403045156: 100%|██████████| 3592/3592 [01:00<00:00, 58.89it/s]\n","epoch:13 loss:19.816462311022523: 100%|██████████| 3592/3592 [01:01<00:00, 58.83it/s]\n","epoch:14 loss:19.765945900389266: 100%|██████████| 3592/3592 [01:01<00:00, 58.60it/s]\n","epoch:15 loss:19.443155782923675: 100%|██████████| 3592/3592 [01:00<00:00, 59.60it/s]\n","epoch:16 loss:19.712545438505835: 100%|██████████| 3592/3592 [01:00<00:00, 59.26it/s]\n","epoch:17 loss:19.131200384522877: 100%|██████████| 3592/3592 [01:01<00:00, 58.39it/s]\n","epoch:18 loss:18.983422040872977: 100%|██████████| 3592/3592 [01:01<00:00, 58.85it/s]\n","epoch:19 loss:18.867750502774353: 100%|██████████| 3592/3592 [01:01<00:00, 58.57it/s]\n","epoch:20 loss:18.399347270982044: 100%|██████████| 3592/3592 [01:00<00:00, 59.56it/s]\n","epoch:21 loss:18.383475940716057: 100%|██████████| 3592/3592 [01:01<00:00, 58.28it/s]\n","epoch:22 loss:18.19656544080822: 100%|██████████| 3592/3592 [01:01<00:00, 58.10it/s]\n","epoch:23 loss:18.042284126204706: 100%|██████████| 3592/3592 [01:02<00:00, 57.78it/s]\n","epoch:24 loss:17.8298724414511: 100%|██████████| 3592/3592 [01:03<00:00, 56.95it/s]\n","epoch:25 loss:17.892769153638483: 100%|██████████| 3592/3592 [01:02<00:00, 57.05it/s]\n","epoch:26 loss:17.298588540015054: 100%|██████████| 3592/3592 [01:02<00:00, 57.42it/s]\n","epoch:27 loss:17.223309377419927: 100%|██████████| 3592/3592 [01:02<00:00, 57.18it/s]\n","epoch:28 loss:17.152681905734735: 100%|██████████| 3592/3592 [01:01<00:00, 57.98it/s]\n","epoch:29 loss:16.90589493423498: 100%|██████████| 3592/3592 [01:01<00:00, 58.55it/s]\n","epoch:30 loss:16.809544689306154: 100%|██████████| 3592/3592 [01:01<00:00, 58.03it/s]\n"]}]},{"cell_type":"markdown","source":["# 모델 성능 평가에 필요한 요소 정의"],"metadata":{"id":"xWsUZX4f2fV2"}},{"cell_type":"code","source":["# 인코더 가중치 불러오기\n","encoder.load_state_dict(torch.load(\"attn_enc.pth\", map_location=device))\n","# 디코더 가중치 불러오기\n","decoder.load_state_dict(torch.load(\"attn_dec.pth\", map_location=device))\n","\n","\n","# ❶불러올 영어 문장을 랜덤하게 지정\n","idx = random.randint(0, len(dataset))\n","# 테스트에 사용할 문장\n","input_sentence = dataset.eng_corpus[idx]\n","# 신경망이 번역한 문장\n","pred_sentence = \"\"\n","\n","data, label = dataset[idx]\n","data = torch.tensor(data, dtype=torch.long).to(device)\n","label = torch.tensor(label, dtype=torch.long).to(device)\n","\n","# ➋인코더의 초기 은닉 상태 정의\n","encoder_hidden = torch.zeros(1, 1, 64).to(device)\n","# 인코더 출력을 담기위한 변수\n","encoder_outputs = torch.zeros(11, 64).to(device)"],"metadata":{"id":"96gq4Lphm1Gj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 인코더 동작"],"metadata":{"id":"o9MzH8bN2z5v"}},{"cell_type":"code","source":["for ei in range(len(data)):\n","   # ➊한 단어씩 인코더에 넣어줌\n","   encoder_output, encoder_hidden = encoder(\n","       data[ei], encoder_hidden)\n","\n","   # ➋인코더의 출력을 저장\n","   encoder_outputs[ei] = encoder_output[0, 0]\n","\n","\n","# ➌디코더의 초기 입력\n","# 0은 <SOS>토큰\n","decoder_input = torch.tensor([[0]]).to(device)\n","\n","# ➍인코더의 마지막 은닉 상태를 디코더의 초기 은닉 상태로\n","decoder_hidden = encoder_hidden"],"metadata":{"id":"la5BGiB520bv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 디코더 동작"],"metadata":{"id":"do9gDbpd22LL"}},{"cell_type":"code","source":["for di in range(11):\n","    # ➊가장 높은 확률을 갖는 단어의 요소를 구함\n","    decoder_output = decoder(\n","                        decoder_input, decoder_hidden, encoder_outputs)\n","    topv, topi = decoder_output.topk(1)\n","    decoder_input = topi.squeeze().detach()\n","\n","    # ➋<EOS> 토큰을 만나면 중지\n","    if decoder_input.item() == 1:\n","        break\n","\n","    # ➌가장 높은 단어를 문자열에 추가\n","    pred_sentence += list(dataset.korBOW.keys())[decoder_input] + \" \"\n","\n","    print(decoder_input)\n","\n","print(input_sentence)  # 영어 문장\n","print(pred_sentence)  # 한글 문장"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2moagtO25b0","executionInfo":{"status":"ok","timestamp":1699062193796,"user_tz":-540,"elapsed":0,"user":{"displayName":"류현승","userId":"17577509123803272784"}},"outputId":"ad6c86df-76f2-44b8-f5a6-8b2390b27801"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["tensor(384, device='cuda:0')\n","tensor(384, device='cuda:0')\n","tensor(384, device='cuda:0')\n","tensor(384, device='cuda:0')\n","tensor(384, device='cuda:0')\n","tensor(384, device='cuda:0')\n","tensor(384, device='cuda:0')\n","tensor(384, device='cuda:0')\n","tensor(384, device='cuda:0')\n","tensor(384, device='cuda:0')\n","tensor(384, device='cuda:0')\n","no one was excluded\n","아무도 아무도 아무도 아무도 아무도 아무도 아무도 아무도 아무도 아무도 아무도 \n"]}]},{"cell_type":"code","source":["-"],"metadata":{"id":"2OFlJFy_5CaL"},"execution_count":null,"outputs":[]}]}